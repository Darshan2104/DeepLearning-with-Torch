{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b898735c-d019-4eda-9522-265d18b09de8",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "- P(X|y) --> likelihood of feature given the class\n",
    "- P(X) --> Evidence/ Total probability\n",
    "- P(y) --> Prior probability of given class\n",
    "- P(y|X) --> posterior probability of class y given input data X\n",
    "\n",
    "- Task: find to posterior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e2d10e-a4cb-4a41-9fea-aee1c82d1cf8",
   "metadata": {},
   "source": [
    "- P(y|X) = P(X|y)*P(y) / P(X)\n",
    "- posterior = likelihood * prior / total prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e74c8d-c4e7-4b98-8d6d-b4fe00afedc2",
   "metadata": {},
   "source": [
    "- It is used when data are in continuous nature\n",
    "- it uses gaussian distribution for likelihood estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e03031-bf53-43f2-86ce-33f271731660",
   "metadata": {},
   "source": [
    "The probability density function (PDF) of a Gaussian distribution is given by:\n",
    "\n",
    "$$\n",
    "f(x \\mid \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2 \\sigma^2}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( x \\) is the variable\n",
    "- \\( \\mu \\) is the mean\n",
    "- \\( \\sigma^2 \\) is the variance (with \\( \\sigma \\) as the standard deviation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbda296-ec22-459e-8d1f-024a7d0ac9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96fc703f-05de-4722-8512-90c43f5554e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.classes = None # list of all the unique class lables\n",
    "        self.class_priors = {} # prior prob of each classes\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "    \n",
    "    # It is used to fit input data to model\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.class_priors = defaultdict(float)\n",
    "        self.mean = defaultdict(np.ndarray)\n",
    "        self.var = defaultdict(np.ndarray)\n",
    "        \n",
    "        # for each class we will calculate --> prior prob, mean and var\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]  # Select only rows where the class label is c\n",
    "            # number of example devide by total examples for specific class prior\n",
    "            self.class_priors[c] = X_c.shape[0]/n_samples\n",
    "            self.mean[c]= np.mean(X_c, axis=0)\n",
    "            self.var[c] = np.var(X_c, axis=0)\n",
    "                    \n",
    "    def _calculate_likelihood(self, mean, var, x):\n",
    "        # Gaussian likelihood calculation\n",
    "        eps = 1e-6  # Small epsilon to avoid division by zero\n",
    "        coeff = 1.0 / np.sqrt(2.0 * np.pi * var + eps)\n",
    "        exponent = np.exp(-(x - mean) ** 2 / (2.0 * var + eps))\n",
    "        return coeff * exponent\n",
    "\n",
    "    def _calculate_posterior(self, X):\n",
    "        posterior_for_each_class = []\n",
    "        for c in self.classes:\n",
    "            #  for each class we will calculate log prior (log P(y))\n",
    "            #  and also we will calculate log likelihood ( log (P(x|y)) ---> log(p(x1|y)*p(x2|y).....p(xn|y))) ---> (sum(log(xi|y)))\n",
    "            #  log postirior = log(prior) + log(likelihood)\n",
    "            prior = np.log(self.class_priors[c])\n",
    "            likelihood = np.sum(np.log(self._calculate_likelihood(self.mean[c], self.var[c], X)))\n",
    "            postirior = prior + likelihood\n",
    "            posterior_for_each_class.append(postirior)\n",
    "                    \n",
    "        return self.classes[np.argmax(posterior_for_each_class)]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self._calculate_posterior(x) for x in X])\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2fc876-be06-4dba-9d25-1a07b0ae4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate a dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create an instance of the Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNaiveBayes()\n",
    "\n",
    "# Train the model\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c78e585-406b-4cbe-8280-380845ab50db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25093198, -1.06429142, -2.23823123, -0.91454716,  1.26128601])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f7d5037-9e82-488d-85c8-777d2883a13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = gnb.accuracy(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd061de-c8b3-4311-84a5-d65165589e0c",
   "metadata": {},
   "source": [
    "## Using inbuilt library..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8db53a7-8125-4cc7-9cd8-00021f034497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate a sample dataset with continuous features\n",
    "X, y = make_classification(n_samples=1000, n_features=5, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate the Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Gaussian Naive Bayes Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01626119-f241-40d5-9cf5-c9b2bbadcf7f",
   "metadata": {},
   "source": [
    "### It is used when data is not in continuous nature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe93e76e-54ef-469f-be31-54588e22c2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
