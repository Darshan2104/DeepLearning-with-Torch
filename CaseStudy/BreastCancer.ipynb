{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: Build an ANN for Binary Classification on the Breast Cancer Dataset\n",
        "🎯 Objective:\n",
        "Train an ANN on the Wisconsin Breast Cancer Dataset using Keras, and demonstrate understanding of:\n",
        "- Model architecture (ANN, not CNN)\n",
        "- Batch normalization\n",
        "- Regularization (Dropout or L2)\n",
        "- Optimizers and backpropagation\n",
        "- Overfitting mitigation\n",
        "\n",
        "## Instructions\n",
        "1. Load the Breast Cancer dataset from sklearn.datasets.\n",
        "\n",
        "2. Preprocess the data:\n",
        "  - Standardize the features using StandardScaler\n",
        "  - Train/test split (80/20)\n",
        "\n",
        "3. Build a Keras-based ANN with:\n",
        "  - At least 2 hidden layers using any AF\n",
        "  - Batch Normalization\n",
        "  - Dropout or L2 regularization\n",
        "\n",
        "\n",
        "4. Compile the model using:\n",
        "  - Adam optimizer\n",
        "  - Binary Crossentropy\n",
        "  - Accuracy as a metric\n",
        "\n",
        "\n",
        "5. Train with:\n",
        "  - Batch size = 32\n",
        "  - EarlyStopping on validation loss\n",
        "\n",
        "6.  Evaluate on test set and print final accuracy\n",
        "\n",
        "7. Add inline comments explaining:\n",
        "  - Why batch norm or dropout was used\n",
        "  - How backprop works in their model\n",
        "  - Why that optimizer was chosen"
      ],
      "metadata": {
        "id": "swyJnWOH5K8G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Load the Breast Cancer dataset from sklearn.datasets.\n"
      ],
      "metadata": {
        "id": "8uytvfpp6OwQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SelvUQFt5Bg7",
        "outputId": "1bb33205-f8b6-4f1c-97a8-d48ae6c8ec01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (569, 30)\n",
            "Target shape: (569,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Features (X) and target labels (y)\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Feature names and target names (optional)\n",
        "feature_names = data.feature_names\n",
        "target_names = data.target_names\n",
        "\n",
        "# Checking the shape\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preprocess the data:\n",
        "  - Standardize the features using StandardScaler\n",
        "  - Train/test split (80/20)"
      ],
      "metadata": {
        "id": "v-WlpcGmRuUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the data into 80% train and 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize the features (fit on train, transform both train and test)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Check the shape of the outputs\n",
        "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
        "print(\"X_test_scaled shape:\", X_test_scaled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDRqOAzV6bEw",
        "outputId": "a05ab498-bc74-4c05-eef9-7abdae5b9711"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_scaled shape: (455, 30)\n",
            "X_test_scaled shape: (114, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Build a Keras-based ANN with:\n",
        "  - At least 2 hidden layers using any AF\n",
        "  - Batch Normalization\n",
        "  - Dropout or L2 regularization\n"
      ],
      "metadata": {
        "id": "0o76lxwXUGMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers"
      ],
      "metadata": {
        "id": "Q28gkbIC6qrW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (30,)"
      ],
      "metadata": {
        "id": "HhKPjtwNSouq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(X_train_scaled.shape[1],)),\n",
        "\n",
        "    layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(1e-4)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "LBOVINYOSdA0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U78uXJW6TijD",
        "outputId": "2148482e-6ffc-48bb-d81b-afb2a9bb0f01"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Sequential name=sequential_2, built=True>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Compile the model using:\n",
        "  - Adam optimizer\n",
        "  - Binary Crossentropy\n",
        "  - Accuracy as a metric\n"
      ],
      "metadata": {
        "id": "K9iBP18kUOuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),   # Customize learning rate if needed\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "ZQWuO2JxTjwE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Train with:\n",
        "  - Batch size = 32\n",
        "  - EarlyStopping on validation loss\n"
      ],
      "metadata": {
        "id": "oTnLW3VHUVmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',     # Watch validation loss\n",
        "    patience=5,             # Wait 5 epochs for improvement\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,   # 20% of training set used for validation\n",
        "    callbacks=[early_stop],\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APWBN0AsUXLE",
        "outputId": "96948d0e-a680-4bcc-b072-e00c6c60e3bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "12/12 - 4s - 303ms/step - accuracy: 0.8984 - loss: 0.4023 - val_accuracy: 0.9890 - val_loss: 0.2413\n",
            "Epoch 2/50\n",
            "12/12 - 1s - 66ms/step - accuracy: 0.9588 - loss: 0.2218 - val_accuracy: 0.9780 - val_loss: 0.2150\n",
            "Epoch 3/50\n",
            "12/12 - 0s - 32ms/step - accuracy: 0.9698 - loss: 0.2155 - val_accuracy: 0.9670 - val_loss: 0.2261\n",
            "Epoch 4/50\n",
            "12/12 - 0s - 32ms/step - accuracy: 0.9533 - loss: 0.2154 - val_accuracy: 0.9670 - val_loss: 0.2138\n",
            "Epoch 5/50\n",
            "12/12 - 1s - 52ms/step - accuracy: 0.9780 - loss: 0.1953 - val_accuracy: 0.9780 - val_loss: 0.2177\n",
            "Epoch 6/50\n",
            "12/12 - 0s - 32ms/step - accuracy: 0.9670 - loss: 0.2024 - val_accuracy: 0.9780 - val_loss: 0.2154\n",
            "Epoch 7/50\n",
            "12/12 - 0s - 32ms/step - accuracy: 0.9725 - loss: 0.1965 - val_accuracy: 0.9670 - val_loss: 0.2099\n",
            "Epoch 8/50\n",
            "12/12 - 1s - 53ms/step - accuracy: 0.9725 - loss: 0.1749 - val_accuracy: 0.9670 - val_loss: 0.2177\n",
            "Epoch 9/50\n",
            "12/12 - 0s - 31ms/step - accuracy: 0.9643 - loss: 0.2399 - val_accuracy: 0.9780 - val_loss: 0.1952\n",
            "Epoch 10/50\n",
            "12/12 - 0s - 32ms/step - accuracy: 0.9863 - loss: 0.1663 - val_accuracy: 0.9780 - val_loss: 0.2052\n",
            "Epoch 11/50\n",
            "12/12 - 0s - 30ms/step - accuracy: 0.9725 - loss: 0.1945 - val_accuracy: 0.9780 - val_loss: 0.1981\n",
            "Epoch 12/50\n",
            "12/12 - 1s - 54ms/step - accuracy: 0.9808 - loss: 0.1574 - val_accuracy: 0.9890 - val_loss: 0.1794\n",
            "Epoch 13/50\n",
            "12/12 - 1s - 54ms/step - accuracy: 0.9835 - loss: 0.1424 - val_accuracy: 0.9890 - val_loss: 0.1757\n",
            "Epoch 14/50\n",
            "12/12 - 0s - 34ms/step - accuracy: 0.9945 - loss: 0.1226 - val_accuracy: 0.9670 - val_loss: 0.1687\n",
            "Epoch 15/50\n",
            "12/12 - 1s - 49ms/step - accuracy: 0.9918 - loss: 0.1209 - val_accuracy: 0.9890 - val_loss: 0.1616\n",
            "Epoch 16/50\n",
            "12/12 - 1s - 55ms/step - accuracy: 1.0000 - loss: 0.1098 - val_accuracy: 0.9890 - val_loss: 0.1562\n",
            "Epoch 17/50\n",
            "12/12 - 1s - 49ms/step - accuracy: 0.9890 - loss: 0.1277 - val_accuracy: 0.9780 - val_loss: 0.1507\n",
            "Epoch 18/50\n",
            "12/12 - 1s - 52ms/step - accuracy: 0.9863 - loss: 0.1384 - val_accuracy: 0.9780 - val_loss: 0.1522\n",
            "Epoch 19/50\n",
            "12/12 - 0s - 33ms/step - accuracy: 0.9835 - loss: 0.1418 - val_accuracy: 0.9780 - val_loss: 0.1498\n",
            "Epoch 20/50\n",
            "12/12 - 0s - 35ms/step - accuracy: 0.9863 - loss: 0.1314 - val_accuracy: 0.9780 - val_loss: 0.1462\n",
            "Epoch 21/50\n",
            "12/12 - 1s - 47ms/step - accuracy: 0.9918 - loss: 0.1396 - val_accuracy: 0.9890 - val_loss: 0.1369\n",
            "Epoch 22/50\n",
            "12/12 - 1s - 66ms/step - accuracy: 0.9643 - loss: 0.2128 - val_accuracy: 0.9890 - val_loss: 0.1486\n",
            "Epoch 23/50\n",
            "12/12 - 1s - 47ms/step - accuracy: 0.9808 - loss: 0.1417 - val_accuracy: 0.9560 - val_loss: 0.1640\n",
            "Epoch 24/50\n",
            "12/12 - 1s - 49ms/step - accuracy: 0.9670 - loss: 0.1836 - val_accuracy: 0.9780 - val_loss: 0.1673\n",
            "Epoch 25/50\n",
            "12/12 - 1s - 51ms/step - accuracy: 0.9835 - loss: 0.1336 - val_accuracy: 0.9890 - val_loss: 0.1336\n",
            "Epoch 26/50\n",
            "12/12 - 1s - 45ms/step - accuracy: 0.9835 - loss: 0.1417 - val_accuracy: 0.9890 - val_loss: 0.1289\n",
            "Epoch 27/50\n",
            "12/12 - 0s - 41ms/step - accuracy: 0.9835 - loss: 0.1436 - val_accuracy: 0.9780 - val_loss: 0.1512\n",
            "Epoch 28/50\n",
            "12/12 - 0s - 33ms/step - accuracy: 0.9918 - loss: 0.1226 - val_accuracy: 1.0000 - val_loss: 0.1184\n",
            "Epoch 29/50\n",
            "12/12 - 0s - 31ms/step - accuracy: 0.9918 - loss: 0.1180 - val_accuracy: 1.0000 - val_loss: 0.1174\n",
            "Epoch 30/50\n",
            "12/12 - 0s - 31ms/step - accuracy: 0.9945 - loss: 0.1091 - val_accuracy: 1.0000 - val_loss: 0.1109\n",
            "Epoch 31/50\n",
            "12/12 - 0s - 31ms/step - accuracy: 0.9890 - loss: 0.1254 - val_accuracy: 1.0000 - val_loss: 0.1107\n",
            "Epoch 32/50\n",
            "12/12 - 1s - 53ms/step - accuracy: 0.9945 - loss: 0.1114 - val_accuracy: 0.9890 - val_loss: 0.1332\n",
            "Epoch 33/50\n",
            "12/12 - 1s - 53ms/step - accuracy: 0.9890 - loss: 0.1233 - val_accuracy: 0.9780 - val_loss: 0.1230\n",
            "Epoch 34/50\n",
            "12/12 - 0s - 32ms/step - accuracy: 0.9945 - loss: 0.1201 - val_accuracy: 0.9890 - val_loss: 0.1135\n",
            "Epoch 35/50\n",
            "12/12 - 0s - 31ms/step - accuracy: 0.9945 - loss: 0.1066 - val_accuracy: 1.0000 - val_loss: 0.1099\n",
            "Epoch 36/50\n",
            "12/12 - 1s - 52ms/step - accuracy: 0.9973 - loss: 0.1021 - val_accuracy: 1.0000 - val_loss: 0.1105\n",
            "Epoch 37/50\n",
            "12/12 - 0s - 30ms/step - accuracy: 0.9945 - loss: 0.1035 - val_accuracy: 1.0000 - val_loss: 0.1147\n",
            "Epoch 38/50\n",
            "12/12 - 0s - 33ms/step - accuracy: 0.9890 - loss: 0.1092 - val_accuracy: 1.0000 - val_loss: 0.1154\n",
            "Epoch 39/50\n",
            "12/12 - 1s - 49ms/step - accuracy: 0.9945 - loss: 0.1018 - val_accuracy: 0.9890 - val_loss: 0.1199\n",
            "Epoch 40/50\n",
            "12/12 - 1s - 54ms/step - accuracy: 0.9890 - loss: 0.1165 - val_accuracy: 0.9780 - val_loss: 0.1254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.  Evaluate on test set and print final accuracy"
      ],
      "metadata": {
        "id": "YvmQTVzwUtZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "\n",
        "# Print results\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acQ_ihbYUv_H",
        "outputId": "381f11c8-a0d3-4775-d603-482a5a575c86"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9825\n",
            "Test Loss: 0.1697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Add inline comments explaining:\n",
        "  - Why batch norm or dropout was used\n",
        "  - How backprop works in their model\n",
        "  - Why that optimizer was chosen"
      ],
      "metadata": {
        "id": "9h4gzdDpUwlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "wH8AsX9gUw6y",
        "outputId": "54720db1-d45c-47bb-fa59-f61633165e4e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │        \u001b[38;5;34m31,744\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m1,025\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,744</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,263,493\u001b[0m (12.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,263,493</span> (12.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,086,465\u001b[0m (4.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,086,465</span> (4.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,096\u001b[0m (16.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> (16.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,172,932\u001b[0m (8.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,172,932</span> (8.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With Pytorch"
      ],
      "metadata": {
        "id": "lJiBYtx_WRUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "wLGKBes2VpA0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ 2. Define the Model ------------------\n",
        "class BreastCancerNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(30, 64)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "        return torch.sigmoid(self.fc3(x))\n",
        "\n",
        "model = BreastCancerNet()\n",
        "\n",
        "# ------------------ 3. Define Loss, Optimizer ------------------\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)  # L2 reg via weight_decay"
      ],
      "metadata": {
        "id": "xjnJ7ei6Y0Is"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ 4. Training with EarlyStopping ------------------\n",
        "epochs = 50\n",
        "patience = 5\n",
        "best_val_loss = float('inf')\n",
        "counter = 0\n",
        "\n",
        "val_split = 0.2\n",
        "val_size = int(len(X_train_tensor) * val_split)\n",
        "\n",
        "# Validation data\n",
        "X_val_tensor = X_train_tensor[:val_size]\n",
        "y_val_tensor = y_train_tensor[:val_size]\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation loss\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_preds = model(X_val_tensor)\n",
        "        val_loss = criterion(val_preds, y_val_tensor)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Val Loss: {val_loss.item():.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss.item() < best_val_loss:\n",
        "        best_val_loss = val_loss.item()\n",
        "        best_model_state = model.state_dict()\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# Restore best model\n",
        "model.load_state_dict(best_model_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcMZXiriZLQU",
        "outputId": "bb112c67-1870-4555-e1dd-8ac6c3fcc6c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Val Loss: 0.5410\n",
            "Epoch 2, Val Loss: 0.3981\n",
            "Epoch 3, Val Loss: 0.3411\n",
            "Epoch 4, Val Loss: 0.3127\n",
            "Epoch 5, Val Loss: 0.2832\n",
            "Epoch 6, Val Loss: 0.2533\n",
            "Epoch 7, Val Loss: 0.2387\n",
            "Epoch 8, Val Loss: 0.2230\n",
            "Epoch 9, Val Loss: 0.2061\n",
            "Epoch 10, Val Loss: 0.1973\n",
            "Epoch 11, Val Loss: 0.1723\n",
            "Epoch 12, Val Loss: 0.1599\n",
            "Epoch 13, Val Loss: 0.1457\n",
            "Epoch 14, Val Loss: 0.1330\n",
            "Epoch 15, Val Loss: 0.1245\n",
            "Epoch 16, Val Loss: 0.1179\n",
            "Epoch 17, Val Loss: 0.1104\n",
            "Epoch 18, Val Loss: 0.1055\n",
            "Epoch 19, Val Loss: 0.1013\n",
            "Epoch 20, Val Loss: 0.0996\n",
            "Epoch 21, Val Loss: 0.0860\n",
            "Epoch 22, Val Loss: 0.0957\n",
            "Epoch 23, Val Loss: 0.0877\n",
            "Epoch 24, Val Loss: 0.0864\n",
            "Epoch 25, Val Loss: 0.0816\n",
            "Epoch 26, Val Loss: 0.0753\n",
            "Epoch 27, Val Loss: 0.0739\n",
            "Epoch 28, Val Loss: 0.0838\n",
            "Epoch 29, Val Loss: 0.0710\n",
            "Epoch 30, Val Loss: 0.0663\n",
            "Epoch 31, Val Loss: 0.0621\n",
            "Epoch 32, Val Loss: 0.0615\n",
            "Epoch 33, Val Loss: 0.0576\n",
            "Epoch 34, Val Loss: 0.0614\n",
            "Epoch 35, Val Loss: 0.0578\n",
            "Epoch 36, Val Loss: 0.0510\n",
            "Epoch 37, Val Loss: 0.0602\n",
            "Epoch 38, Val Loss: 0.0629\n",
            "Epoch 39, Val Loss: 0.0517\n",
            "Epoch 40, Val Loss: 0.0524\n",
            "Epoch 41, Val Loss: 0.0552\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------ 5. Evaluate on Test Set ------------------\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test_tensor)\n",
        "    y_pred_class = (y_pred > 0.5).float()\n",
        "    test_accuracy = (y_pred_class == y_test_tensor).float().mean()\n",
        "\n",
        "print(f\"\\nFinal Test Accuracy: {test_accuracy.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C46WrlB0a32S",
        "outputId": "b256f414-cb3d-44a0-b238-8ab18acf0a0c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Test Accuracy: 0.9737\n"
          ]
        }
      ]
    }
  ]
}